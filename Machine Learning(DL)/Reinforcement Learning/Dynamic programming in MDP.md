References: 
Chapter 4 in Sutton book, 

DP can be used to compute the value functions.


Value Iteration
Policy Iteration

In Dynamic programming we need a model(agent knows the MDP transition and rewards) and agent does **planning** (once model is available agent need to plan its action in each state). There is no real learning by the agent in Dynamic programming method.