1. Distributed file systems such as GFS store files in chunks. The size of a chunk has implications on the system’s performance. What are the advantages and disadvantages of storing files in large chunks? (5 points)

**Concept**: GFS
[[GFS]]
'Why Large Chunks' section


2. Explain briefly the similarities and differences of document-based and column oriented databases. What is the difference between storing data in row model and column model? When is better to use the column model? (5 points)
**Concepts**: databases
**Answer**:
- *Similarities*: 
Both are NoSQL Databases, which means they are designed to handle large volumes of unstructured or semi-structured data.

Both allow for flexible schemas, where the structure of the data can vary within the same collection or table.

Both are designed for horizontal scalability, allowing to add more servers to handle increasing data loads.

- *Difference*:
Document-based: store data in documents, in formats like JSON. Column-oriented: store data in columns rather than rows.

*When to use column model*:
Perform analytical queries that involve aggregations, filtering, and calculations on large datasets. Better for row model since it is faster when quering.

You are dealing with data warehousing, business intelligence, and data analytics use cases where performance and storage efficiency are critical.(Apache Cassandra, HBase, or Google Bigtable)

...
3. Assume we want to implement a MapReduce code to multiply a one-dimensional matrix with a two-dimensional matrix. Briefly explain what map and reduce functions should do. (5 points) 
	Reminder. The matrix product of matrices A and B is a third matrix C, where C = AB. If A is of shape m × n and B is of shape n × p, then C is of shape m × p, such that:
![[Pasted image 20231023202621.png]]
5. Explain how does using DataFrame in Spark improve the programming performance compared to RDD. What is the relation between DataFrame and DataSet in Spark? (5 points)
**Answer:**
DataFrame elements are Rows, which are generic untyped JVM objects
Scala compiler cannot type check Spark SQL schemas in DataFrames


6. Explain briefly how does spark join two tables, if (5 points) 
(a) both tables are so big that none of them can be loaded into memory of one computer 
(b) one table is big and the other one is small, such that only the small one can be loaded in memory of one computer. (same question in [[Exam-2022]]/Spark)


8. How can a batch system be used to process streams, and how can a streaming system be used to process batches? (5 points)



9. Explain how Kafka provides scalability and fault tolerance? (4 points)




10. Compare the graph processing models in Pregel, GraphLab, X-Stream. (6 points)


11. Assume we have two types of resources in the system, i.e., CPU and Memory. In total we have 10 CPU and 20GB RAM. There are two users in the systems. User 1 needs h1CP U, 4GBi per task, and user 2 needs h2CP U, 1GBi per task. How do you share the resources fairly among these two users, considering the asset fairness and DRF. (5 points)

